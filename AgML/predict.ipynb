{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bolift\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cloudpickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as font_manager\n",
    "import urllib.request\n",
    "\n",
    "urllib.request.urlretrieve(\n",
    "    \"https://github.com/google/fonts/raw/main/ofl/ibmplexmono/IBMPlexMono-Regular.ttf\",\n",
    "    \"IBMPlexMono-Regular.ttf\",\n",
    ")\n",
    "fe = font_manager.FontEntry(fname=\"IBMPlexMono-Regular.ttf\", name=\"plexmono\")\n",
    "font_manager.fontManager.ttflist.append(fe)\n",
    "plt.rcParams.update(\n",
    "    {\n",
    "        \"axes.facecolor\": \"#f5f4e9\",\n",
    "        \"grid.color\": \"#AAAAAA\",\n",
    "        \"axes.edgecolor\": \"#333333\",\n",
    "        \"figure.facecolor\": \"#FFFFFF\",\n",
    "        \"axes.grid\": False,\n",
    "        \"axes.prop_cycle\": plt.cycler(\"color\", plt.cm.Dark2.colors),\n",
    "        \"font.family\": fe.name,\n",
    "        \"figure.figsize\": (5.0, 5.0 / 1.2),\n",
    "        \"ytick.left\": True,\n",
    "        \"xtick.bottom\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "import random\n",
    "\n",
    "np.random.seed(0)\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RF baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data/processed_data.csv')\n",
    "df.drop(['OD'], axis=1, inplace=True)\n",
    "df.groupby(['Temperature(C)', 'Doping(%)', 'Time(min)']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = df.keys().tolist().index('Experiment')\n",
    "features = df.keys()[:index]\n",
    "labels = df.keys()[index+1:-6]\n",
    "features, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def train_model(train, test):\n",
    "    model = XGBRegressor(\n",
    "    eval_metric=mean_absolute_error \n",
    "    )\n",
    "\n",
    "    X_train, y_train = train\n",
    "    X_test, y_test = test\n",
    "    model.fit(X_train, y_train, eval_set=[(X_test, y_test)], early_stopping_rounds=5)\n",
    "    \n",
    "    return model\n",
    "\n",
    "models = {}\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "print(train_df.keys())\n",
    "\n",
    "for i, k in enumerate(labels):\n",
    "    # print(k, i, labels[i])\n",
    "    train = (train_df[features], train_df[labels[i]])\n",
    "    test = (test_df[features], test_df[labels[i]])\n",
    "    models[k] = train_model(train, test)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 0\n",
    "sample = test_df.iloc[k:k+1]\n",
    "feats = sample[features]\n",
    "labs = sample[labels]\n",
    "\n",
    "def rmse(a, b):\n",
    "    return np.sqrt(np.mean((a - b)**2))\n",
    "\n",
    "for k in labels:\n",
    "    # print(k, rmse(models[k].predict(feats), labs[k].values))\n",
    "    print(k, models[k].predict(feats), labs[k].values)\n",
    "\n",
    "w = [float(a) for a in sample.iloc[0]['Fl_Wavelengths'][1:-1].split(',')]\n",
    "i = [float(a) for a in sample.iloc[0]['Fluorescence_norm'][1:-1].split(',')]\n",
    "\n",
    "# plt.figure(figsize=(6, 4))\n",
    "plt.plot(w, i, color=\"C0\", label=\"Reference\")\n",
    "# plt.title(f\"{sample.iloc[0]['Experiment']}: {sample.iloc[0]['Temperature(C)']}°C, {sample.iloc[0]['Doping(%)']}%, {sample.iloc[0]['Time(min)']}min\")\n",
    "plt.title(f\"XGBoost Model Prediction: Spectra Metrics\")\n",
    "plt.axvline(x = models['Peak1'].predict(sample[features]), color = 'C1', linestyle = '--', label = 'Peak1')\n",
    "plt.axvline(x = models['Peak2'].predict(sample[features]), color = 'C3', linestyle = '--', label = 'Peak2')\n",
    "# change plt figsize\n",
    "plt.xlabel(\"Wavelength (nm)\")\n",
    "plt.ylabel(\"Normalized fluorescence (a.u.)\")\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectra output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data/fl_spectra_data.csv')\n",
    "df.drop(['OD'], axis=1, inplace=True)\n",
    "df.groupby(['Experiment', 'Temperature(C)', 'Doping(%)', 'Time(min)']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = df.keys().tolist().index('Experiment')\n",
    "features = list(df.keys()[:index]) + ['Wavelength(nm)']\n",
    "labels = ['Fluorescence_norm']\n",
    "features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def train_model(train, test):\n",
    "    model = XGBRegressor(\n",
    "    eval_metric=mean_absolute_error \n",
    "    )\n",
    "    \n",
    "    X_train, y_train = train[train.columns.difference(['Fluorescence', 'Fluorescence_norm'])], train['Fluorescence_norm']\n",
    "    X_test, y_test = test[test.columns.difference(['Fluorescence', 'Fluorescence_norm'])], test['Fluorescence_norm']\n",
    "    model.fit(X_train, y_train, eval_set=[(X_test, y_test)], early_stopping_rounds=5)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def test_model(model, validation):\n",
    "    val_feats = validation[validation.columns.difference(['Fluorescence', 'Fluorescence_norm'])]\n",
    "    val_labels = validation[\"Fluorescence_norm\"]\n",
    "\n",
    "    pred = model.predict(val_feats)\n",
    "    return (pred, val_labels.to_numpy(), val_feats['Wavelength(nm)'].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_out = []\n",
    "i=0\n",
    "for group, validation in df.groupby(['Experiment', 'Temperature(C)', 'Doping(%)', 'Time(min)']):\n",
    "    data = df.copy()\n",
    "    exp, T, d, t = group\n",
    "    validation = validation[features + labels]\n",
    "\n",
    "    # validation = data.query(\n",
    "    #     f'`Temperature(C)` == {T} & `Doping(%)` == {d} & `Time` == {t}'\n",
    "    # )\n",
    "    train_df = data.drop(validation.index)\n",
    "    train, test = train_test_split(train_df[features + labels], test_size=0.2, random_state=42)\n",
    "\n",
    "    model = train_model(train, test)\n",
    "\n",
    "    prediction = test_model(model, validation)\n",
    "    one_out.append((group, prediction))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "fig, axs = plt.subplots(1, 4, figsize=(16, 4))\n",
    "i=0\n",
    "for group, predictions in one_out:\n",
    "    axs = axs.flatten()\n",
    "    exp, T, d, t = group\n",
    "    if exp not in [\"8_NPL-13_(3-8-23)\", \"7_NPL-12_(3-8-23)\"] or T != 0.0 or t != 60:\n",
    "        continue\n",
    "    # title = f\"{exp}: T: {T}ºC, Doping: {d}%, Time: {t}min\"\n",
    "    title = f\"Doping: {d}%\"\n",
    "\n",
    "    if i == 0:\n",
    "        axs[i].plot(predictions[2], predictions[0], color=\"C0\", label='Prediction')\n",
    "        axs[i].plot(predictions[2], predictions[1], color=\"C1\", label='labels')\n",
    "    else:\n",
    "        axs[i].plot(predictions[2], predictions[0], color=\"C0\")\n",
    "        axs[i].plot(predictions[2], predictions[1], color=\"C1\")\n",
    "    axs[i].set_title(title)\n",
    "\n",
    "    i+=1 \n",
    "    # plt.savefig(f'preds/{group}.png')\n",
    "fig.legend(loc='center', bbox_to_anchor=(0.5,0), fancybox=True, shadow=True, ncol=2)\n",
    "fig.suptitle(f\"7_NPL-12_(3-8-23) and 8_NPL-13_(3-8-23): T: 25 ºC, Time: 60 min\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "i=0\n",
    "for group, predictions in one_out:\n",
    "    if i == 0:\n",
    "        exp, T, d, t = group\n",
    "        title = f\"{exp}: T: {T}ºC, Doping: {d}%, Time: {t}min\"\n",
    "        plt.figure()\n",
    "        sns.lineplot(x=predictions[2], y=predictions[1], label='Reference')\n",
    "        sns.lineplot(x=predictions[2], y=predictions[0], label='Prediction')\n",
    "        plt.legend()\n",
    "        # plt.savefig(f'preds/{group}.png')\n",
    "        fig.legend(loc='center', bbox_to_anchor=(0.5,0), fancybox=True, shadow=True, ncol=2)\n",
    "        # plt.title(title)\n",
    "        plt.title(\"XGBoost Model Prediction: Entire Spectra\")\n",
    "        plt.legend()\n",
    "        plt.xlabel(\"Wavelength (nm)\")\n",
    "        plt.ylabel(\"Normalized fluorescence (a.u.)\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    i += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "def _get_peaks(x, y):\n",
    "    peaks = []\n",
    "    th = 0.001\n",
    "    for i in range(1, len(x)-1):\n",
    "        if y[i] > y[i-1]+th and y[i] > y[i+1]+th:\n",
    "            peaks.append((x[i], y[i]))\n",
    "    return peaks\n",
    "\n",
    "def get_peaks(x, y):\n",
    "    x = np.array(x)\n",
    "    p1_i = np.where(x == 450)[0][0]\n",
    "    p1_e = np.where(x == 550)[0][0]\n",
    "    p2_i = np.where(x == 550)[0][0]\n",
    "    p2_e = np.where(x == 700)[0][0]\n",
    "\n",
    "    x1 = x[p1_i:p1_e]\n",
    "    y1 = y[p1_i:p1_e]\n",
    "    x2 = x[p2_i:p2_e]\n",
    "    y2 = y[p2_i:p2_e]\n",
    "\n",
    "    return x1[np.argmax(y1)], x2[np.argmax(y2)]\n",
    "\n",
    "def get_area_under_peaks(x, y, norm=None):\n",
    "    if not norm:\n",
    "        return np.trapz(y, x)\n",
    "    \n",
    "    x = np.array(x)\n",
    "    p1_i = np.where(x == 450)[0][0]\n",
    "    p1_e = np.where(x == 550)[0][0]\n",
    "    p2_i = np.where(x == 550)[0][0]\n",
    "    p2_e = np.where(x == 700)[0][0]\n",
    "\n",
    "    x1 = x[p1_i:p1_e]\n",
    "    y1 = y[p1_i:p1_e]\n",
    "    x2 = x[p2_i:p2_e]\n",
    "    y2 = y[p2_i:p2_e]\n",
    "\n",
    "    return np.trapz(y1, x1)/norm, np.trapz(y2, x2)/norm\n",
    "\n",
    "def process_spectrum(x, y, norm_area):\n",
    "    peaks = get_peaks(x, y)\n",
    "    areas = get_area_under_peaks(x, y, norm_area)\n",
    "    return peaks, areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(a, b):\n",
    "    return np.sqrt(np.mean((a - b)**2))\n",
    "\n",
    "pred_dict = {\n",
    "    \"Peak1\": [],\n",
    "    \"Peak2\": [],\n",
    "    \"Area1\": [],\n",
    "    \"Area2\": [],\n",
    "    \"Distance_peaks\": []\n",
    "}\n",
    "label_dict = {\n",
    "    \"Peak1\": [],\n",
    "    \"Peak2\": [],\n",
    "    \"Area1\": [],\n",
    "    \"Area2\": [],\n",
    "    \"Distance_peaks\": []\n",
    "}\n",
    "\n",
    "for group, predictions in one_out:\n",
    "    pred_peak = get_peaks(predictions[2], predictions[0])\n",
    "    pred_norm_area = get_area_under_peaks(predictions[2], predictions[0])\n",
    "    pred_area = get_area_under_peaks(predictions[2], predictions[0], norm=pred_norm_area)\n",
    "\n",
    "    label_peak = get_peaks(predictions[2], predictions[1])\n",
    "    label_norm_area = get_area_under_peaks(predictions[2], predictions[1])\n",
    "    label_area = get_area_under_peaks(predictions[2], predictions[1], norm=label_norm_area)\n",
    "    \n",
    "    pred_dict[\"Peak1\"].append(pred_peak[0])\n",
    "    pred_dict[\"Peak2\"].append(pred_peak[1])\n",
    "    pred_dict[\"Area1\"].append(pred_area[0])\n",
    "    pred_dict[\"Area2\"].append(pred_area[1])\n",
    "    pred_dict[\"Distance_peaks\"].append(pred_peak[1] - pred_peak[0])\n",
    "\n",
    "    label_dict[\"Peak1\"].append(label_peak[0])\n",
    "    label_dict[\"Peak2\"].append(label_peak[1])\n",
    "    label_dict[\"Area1\"].append(label_area[0])\n",
    "    label_dict[\"Area2\"].append(label_area[1])\n",
    "    label_dict[\"Distance_peaks\"].append(label_peak[1] - label_peak[0])\n",
    "    \n",
    "    #plot\n",
    "    # exp, T, d, t = group\n",
    "    # title = f\"{exp}: T: {T}ºC, Doping: {d}%, Time: {t}min\"\n",
    "    # plt.figure()\n",
    "    # sns.lineplot(x=predictions[2], y=predictions[0], label='Prediction').set(title=title)\n",
    "    # sns.lineplot(x=predictions[2], y=predictions[1], label='label')\n",
    "    # plt.legend()\n",
    "    # plt.show()    \n",
    "\n",
    "for k in pred_dict.keys():\n",
    "    print(k, rmse(np.array(pred_dict[k]), np.array(label_dict[k])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bolift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cloudpickle\n",
    "import bolift\n",
    "import seaborn as sns\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"../.env\", override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data/procedures.tsv', sep=\"\\t\")\n",
    "prompts = df['prompt'].tolist()\n",
    "peaks1 = df['peak1'].tolist()\n",
    "peaks2 = df['peak2'].tolist()\n",
    "\n",
    "import numpy as np\n",
    "indexes = np.arange(len(prompts))\n",
    "np.random.shuffle(indexes)\n",
    "split = (len(indexes)-12)/len(indexes)\n",
    "\n",
    "train_indexes = indexes[:int(split*len(indexes))]\n",
    "test_indexes = indexes[int(split*len(indexes)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "asktell1 = bolift.AskTellFewShotTopk(\n",
    "    prefix=\"Complete the scoring ranking the last experiment.\"\\\n",
    "          \" Each answer should be numeric and ends with ###.\" \\\n",
    "          \" Use the following information to complete the prompt: \\n\",\n",
    "    x_formatter=lambda x: f\"the experimental procedure: {x}\",\n",
    "    y_name=\"first peak in the fluorescence spectrum\",\n",
    "    y_formatter=lambda y: f\"{y:.2f}\",\n",
    "    model=\"gpt-4o\",\n",
    "    selector_k=5,\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "asktell2 = bolift.AskTellFewShotTopk(\n",
    "    prefix=\"Complete the scoring ranking the last experiment.\"\\\n",
    "          \" Each answer should be numeric and ends with ###.\" \\\n",
    "          \" Use the following information to complete the prompt: \\n\",\n",
    "    x_formatter=lambda x: f\"the experimental procedure: {x}\",\n",
    "    y_name=\"second peak in the fluorescence spectrum\",\n",
    "    y_formatter=lambda y: f\"{y:.2f}\",\n",
    "    model=\"gpt-4o\",\n",
    "    selector_k=5,\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "for i in train_indexes:\n",
    "    asktell1.tell(prompts[i], peaks1[i])\n",
    "\n",
    "for i in train_indexes:\n",
    "    asktell2.tell(prompts[i], peaks2[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are a bot that can accurately predict chemical and material properties from their synthesis and experimental procedures. Do not explain answers, just provide numerical predictions.\"\n",
    "\n",
    "yhat=[]\n",
    "y=[]\n",
    "for i in test_indexes:\n",
    "  yhat1 = asktell1.predict(prompts[i], system_message=system_message)\n",
    "  yhat2 = asktell2.predict(prompts[i], system_message=system_message)\n",
    "  print(f\"{yhat1.mean():.2f}+/-{yhat1.std():.2f} : {peaks1[i]} // {yhat2.mean():.2f}+/-{yhat2.std():.2f} : {peaks2[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for group, predictions in one_out:\n",
    "    if i == 0:\n",
    "        exp, T, d, t = group\n",
    "        title = f\"{exp}: T: {T}ºC, Doping: {d}%, Time: {t}min\"\n",
    "        plt.figure()\n",
    "        sns.lineplot(x=predictions[2], y=predictions[1], label='Reference')\n",
    "        plt.axvline(x = asktell1.predict(prompts[0]).mean(), color = 'C1', linestyle = '--', label = 'Peak1')\n",
    "        plt.axvline(x = asktell2.predict(prompts[0]).mean(), color = 'C3', linestyle = '--', label = 'Peak2')\n",
    "        fig.legend(loc='center', bbox_to_anchor=(0.5,0), fancybox=True, shadow=True, ncol=2)\n",
    "        # plt.title(title)\n",
    "        plt.title(\"LLM Prediction: Spectra Metrics\")\n",
    "        plt.legend()\n",
    "        plt.xlabel(\"Wavelength (nm)\")\n",
    "        plt.ylabel(\"Normalized fluorescence (a.u.)\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data/procedures_new.tsv', sep=\"\\t\")\n",
    "prompts = df['prompt'].tolist()\n",
    "labels_f = df['obj_f'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "indexes = np.arange(len(prompts))\n",
    "np.random.shuffle(indexes)\n",
    "split = (len(indexes)-12)/len(indexes)\n",
    "\n",
    "train_indexes = indexes[:int(split*len(indexes))]\n",
    "test_indexes = indexes[int(split*len(indexes)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "asktell = bolift.AskTellFewShotTopk(\n",
    "    prefix=\"Complete the distance between the fluorescence peaks in the spectra measured for the last experiment.\"\\\n",
    "          \" Each answer should be numeric and ends with ###.\" \\\n",
    "          \" Use the following information to complete the prompt: \\n\",\n",
    "    x_formatter=lambda x: f\"the experimental procedure: {x}\",\n",
    "    y_name=\"the product of the quantum yield with the area under the fluorescence peak at 650 nm\",\n",
    "    y_formatter=lambda y: f\"{y:.2f}\",\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    selector_k=5,\n",
    "    temperature=0.7,\n",
    ")\n",
    "\n",
    "system_message_path = \"Data/system_message.txt\"\n",
    "inv_system_message_path = \"Data/inv_system_message.txt\"\n",
    "\n",
    "if os.path.exists(system_message_path):\n",
    "    with open(system_message_path, \"r\") as f:\n",
    "        system_message = f.read()\n",
    "else:\n",
    "    system_message = \"\"\n",
    "\n",
    "if os.path.exists(inv_system_message_path):\n",
    "    with open(inv_system_message_path, \"r\") as f:\n",
    "        inv_system_message = f.read()\n",
    "else:\n",
    "    inv_system_message = \"\"\n",
    "\n",
    "for i in train_indexes:\n",
    "  if labels_f[i] >= 0:\n",
    "    asktell.tell(prompts[i], labels_f[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat=[]\n",
    "y=[]\n",
    "for i in test_indexes:\n",
    "  yhat.append(asktell.predict(prompts[i] , system_message=\"\"))\n",
    "  y.append(labels_f[i]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in test_indexes:\n",
    "  print(f\"{prompts[i]} => {labels_f[i]}\")\n",
    "\n",
    "# [f\"{i.mean():.2f}\" for i in yhat], y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(a, b):\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    return np.sqrt(np.mean((a - b)**2))\n",
    "\n",
    "sum = 0\n",
    "print(f\"| {'predicted':^23s} | {'label':^10s} | {'AE':^10s} | \")\n",
    "n = 0\n",
    "for ihat, i in zip(yhat, y):\n",
    "  n+=1\n",
    "  mae = abs(ihat.mean()-i)\n",
    "  print(f\"| {ihat.mean():^10.2f}+/-{ihat.std():^10.2f} | {i:^10.2f} | {mae:^10.2f} |\")\n",
    "  sum += mae\n",
    "print(f\"\\n{'RMSE: ':>20s}{rmse([ihat.mean() for ihat in yhat], y):<18.2f}\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "yhat_mean = [ihat.mean() for ihat in yhat]\n",
    "y_plot    = np.array(y)[np.where(np.array(yhat_mean) <= 1)]\n",
    "yhat_plot = np.array(yhat_mean)[np.where(np.array(yhat_mean) <= 1)]\n",
    "yerr_plot = np.array([ihat.std() for ihat in yhat])[np.where(np.array(yhat_mean) <= 1)]\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.xlabel('Experimental outcome')\n",
    "plt.ylabel('Predicted outcome')\n",
    "plt.plot(y_plot, yhat_plot, 'o')\n",
    "plt.errorbar(y_plot, yhat_plot, yerr=yerr_plot, fmt='none')\n",
    "plt.title('LLM prediction: f = QY * AUC2')\n",
    "plt.plot((0,0.4), (0,0.4), '--')\n",
    "plt.text(0.75, 0.90, f\"RMSE: {rmse(y_plot, yhat_plot):.2f}\", fontsize=12, transform=plt.gca().transAxes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_list = pd.read_csv('Data/procedures.tsv', sep='\\t')\n",
    "prompts, labels_f = proc_list['prompt'].tolist(), proc_list['obj_f'].tolist()\n",
    "\n",
    "pool_type = \"processed\"\n",
    "pool_list = pd.read_csv(f\"Data/pool_{pool_type}.txt\", sep=';')\n",
    "# pool = cloudpickle.load(open(f'Data/pool_{pool_type}.pkl', 'rb'))\n",
    "pool = bolift.Pool(pool_list['prompt'].to_list())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asktell = bolift.AskTellFewShotTopk(\n",
    "    prefix=\"Complete the distance between the fluorescence peaks in the spectra measured for the last experiment.\"\\\n",
    "          \" Each answer should be numeric and ends with ###.\" \\\n",
    "          \" Use the following information to complete the prompt: \\n\",\n",
    "    x_formatter=lambda x: f\"the experimental procedure: {x}\",\n",
    "    y_name=\"the product of the quantum yield with the area under the fluorescence peak at 650 nm\",\n",
    "    y_formatter=lambda y: f\"{y:.2f}\",\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    selector_k=5,\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "system_message_path = \"Data/system_message.txt\"\n",
    "inv_system_message_path = \"Data/inv_system_message.txt\"\n",
    "\n",
    "if os.path.exists(system_message_path):\n",
    "    with open(system_message_path, \"r\") as f:\n",
    "        system_message = f.read()\n",
    "    print(\"Loaded system message\")\n",
    "else:\n",
    "    system_message = \"\"\n",
    "\n",
    "if os.path.exists(inv_system_message_path):\n",
    "    with open(inv_system_message_path, \"r\") as f:\n",
    "        inv_system_message = f.read()\n",
    "    print(\"Loaded inv system message\")\n",
    "else:\n",
    "    inv_system_message = \"\"\n",
    "\n",
    "print(pool)\n",
    "\n",
    "for p,l in zip(prompts, labels_f):\n",
    "  asktell.tell(p, float(l))\n",
    "  try:\n",
    "    pool.choose(p)\n",
    "  except:\n",
    "    continue\n",
    "\n",
    "print(pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(labels_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = asktell.ask(pool, aq_fxn=\"expected_improvement\", k=5, inv_filter=15, aug_random_filter=1, inv_system_message=inv_system_message, system_message=system_message)\n",
    "i = 0\n",
    "for prompt, p in zip(selected[0], asktell.predict(selected[0], system_message=system_message)):\n",
    "    print(f\"{prompt} => {p.mean():.4f} +/- {p.std():.4f}\\n\")\n",
    "    # print(f\"{i+1}: {prompt}\")\n",
    "    i+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for prompt in selected[0]:\n",
    "    print(f\"{i+1}: {prompt}\\n\")\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New exp suggestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_list = pd.read_csv('Data/procedures.tsv', sep='\\t')\n",
    "prompts, labels_f = proc_list['prompt'].tolist(), proc_list['obj_f'].tolist()\n",
    "\n",
    "pool_type = \"processed\"\n",
    "pool_list = pd.read_csv(f\"Data/pool_{pool_type}.txt\", sep=';')\n",
    "# pool = cloudpickle.load(open(f'Data/pool_{pool_type}.pkl', 'rb'))\n",
    "pool = bolift.Pool(pool_list['prompt'].to_list())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asktell = bolift.AskTellFewShotTopk(\n",
    "    prefix=\"Complete the distance between the fluorescence peaks in the spectra measured for the last experiment.\"\\\n",
    "          \" Each answer should be numeric and ends with ###.\" \\\n",
    "          \" Use the following information to complete the prompt: \\n\",\n",
    "    x_formatter=lambda x: f\"the experimental procedure: {x}\",\n",
    "    y_name=\"the product of the quantum yield with the area under the fluorescence peak at 650 nm\",\n",
    "    y_formatter=lambda y: f\"{y:.2f}\",\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    selector_k=5,\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "system_message_path = \"Data/system_message.txt\"\n",
    "inv_system_message_path = \"Data/inv_system_message.txt\"\n",
    "\n",
    "if os.path.exists(system_message_path):\n",
    "    with open(system_message_path, \"r\") as f:\n",
    "        system_message = f.read()\n",
    "    print(\"Loaded system message\")\n",
    "else:\n",
    "    system_message = \"\"\n",
    "\n",
    "if os.path.exists(inv_system_message_path):\n",
    "    with open(inv_system_message_path, \"r\") as f:\n",
    "        inv_system_message = f.read()\n",
    "    print(\"Loaded inv system message\")\n",
    "else:\n",
    "    inv_system_message = \"\"\n",
    "\n",
    "print(pool)\n",
    "\n",
    "for p,l in zip(prompts, labels_f):\n",
    "  asktell.tell(p, float(l))\n",
    "  try:\n",
    "    pool.choose(p)\n",
    "  except:\n",
    "    continue\n",
    "\n",
    "print(pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(labels_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "propts = []\n",
    "preds_mean = []\n",
    "preds_std = []\n",
    "\n",
    "for p in pool:\n",
    "  propts.append(p)\n",
    "  pred = asktell.predict(p, system_message=system_message)\n",
    "  preds_mean.append(pred.mean())\n",
    "  preds_std.append(pred.std())\n",
    "\n",
    "predicted_pool = pd.DataFrame({\n",
    "  'prompt': propts, \n",
    "  'pred_mean': preds_mean,\n",
    "  'pred_std': preds_std\n",
    "  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_pool.sort_values(by='pred_mean', ascending=True, inplace=True)\n",
    "predicted_pool.to_csv(f'Data/predicted_pool_{pool_type}.txt', sep=';', index=False)\n",
    "predicted_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_pool = predicted_pool[predicted_pool['pred_mean'] < 0.7]\n",
    "filtered_pool = filtered_pool[filtered_pool['pred_std'] < 0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot filtered+pool means using pred_std as error\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.errorbar(range(len(filtered_pool)), filtered_pool['pred_mean'],yerr=filtered_pool['pred_std'], fmt='.', alpha=0.2, color='gray')\n",
    "plt.scatter(range(len(filtered_pool)), filtered_pool['pred_mean'], label='Filtered pool')\n",
    "plt.xlabel('Predicted outcome')\n",
    "plt.ylabel('Experiment index')\n",
    "plt.title('Predicted outcomes for the filtered pool')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in [2,4,23, 950,953,947, 965,964,962]:\n",
    "# for l in range(900, 950):\n",
    "  print(f''' ------------ [index: {l}] ------------\n",
    "  prompt: {filtered_pool.iloc[l]['prompt']}\n",
    "  prediction: {filtered_pool.iloc[l]['pred_mean']} +/- {filtered_pool.iloc[l]['pred_std']}\n",
    "  ''')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "doe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
