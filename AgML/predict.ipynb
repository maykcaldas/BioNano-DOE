{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bolift\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as font_manager\n",
    "import urllib.request\n",
    "\n",
    "urllib.request.urlretrieve(\n",
    "    \"https://github.com/google/fonts/raw/main/ofl/ibmplexmono/IBMPlexMono-Regular.ttf\",\n",
    "    \"IBMPlexMono-Regular.ttf\",\n",
    ")\n",
    "fe = font_manager.FontEntry(fname=\"IBMPlexMono-Regular.ttf\", name=\"plexmono\")\n",
    "font_manager.fontManager.ttflist.append(fe)\n",
    "plt.rcParams.update(\n",
    "    {\n",
    "        \"axes.facecolor\": \"#f5f4e9\",\n",
    "        \"grid.color\": \"#AAAAAA\",\n",
    "        \"axes.edgecolor\": \"#333333\",\n",
    "        \"figure.facecolor\": \"#FFFFFF\",\n",
    "        \"axes.grid\": False,\n",
    "        \"axes.prop_cycle\": plt.cycler(\"color\", plt.cm.Dark2.colors),\n",
    "        \"font.family\": fe.name,\n",
    "        \"figure.figsize\": (3.5, 3.5 / 1.2),\n",
    "        \"ytick.left\": True,\n",
    "        \"xtick.bottom\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "import random\n",
    "\n",
    "np.random.seed(0)\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RF baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data/processed_data.csv')\n",
    "df.drop(['OD'], axis=1, inplace=True)\n",
    "df.groupby(['Temperature(C)', 'Doping(%)', 'Time(min)']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = df.keys().tolist().index('Experiment')\n",
    "features = df.keys()[:index]\n",
    "labels = df.keys()[index+1:-3]\n",
    "features, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def train_model(train, test):\n",
    "    model = XGBRegressor(\n",
    "    eval_metric=mean_absolute_error \n",
    "    )\n",
    "\n",
    "    X_train, y_train = train\n",
    "    X_test, y_test = test\n",
    "    model.fit(X_train, y_train, eval_set=[(X_test, y_test)], early_stopping_rounds=5)\n",
    "    \n",
    "    return model\n",
    "\n",
    "models = {}\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "print(len(train_df), len(test_df))\n",
    "for i, k in enumerate(labels):\n",
    "    # print(k, i, labels[i])\n",
    "    train = (train_df[features], train_df[labels[i]])\n",
    "    test = (test_df[features], test_df[labels[i]])\n",
    "    models[k] = train_model(train, test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 11\n",
    "sample = test_df.iloc[k:k+1]\n",
    "feats = sample[features]\n",
    "labs = sample[labels]\n",
    "\n",
    "def rmse(a, b):\n",
    "    return np.sqrt(np.mean((a - b)**2))\n",
    "\n",
    "for k in labels:\n",
    "    # print(k, rmse(models[k].predict(feats), labs[k].values))\n",
    "    print(k, models[k].predict(feats), labs[k].values)\n",
    "\n",
    "w = [float(a) for a in sample.iloc[0]['Wavelengths'][1:-1].split(',')]\n",
    "i = [float(a) for a in sample.iloc[0]['Fluorescence_norm'][1:-1].split(',')]\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(w, i, color=\"C0\")\n",
    "plt.title(f\"{sample.iloc[0]['Experiment']}: {sample.iloc[0]['Temperature(C)']}°C, {sample.iloc[0]['Doping(%)']}%, {sample.iloc[0]['Time(min)']}min\")\n",
    "plt.axvline(x = models['Peak1'].predict(sample[features]), color = 'C1', linestyle = '--')\n",
    "plt.axvline(x = models['Peak2'].predict(sample[features]), color = 'C3', linestyle = '--')\n",
    "# change plt figsize\n",
    "plt.xlabel(\"Wavelength (nm)\")\n",
    "plt.ylabel(\"Normalized fluorescence\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectra output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data/spectra_data.csv')\n",
    "df.drop(['OD'], axis=1, inplace=True)\n",
    "df.groupby(['Experiment', 'Temperature(C)', 'Doping(%)', 'Time(min)']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = df.keys().tolist().index('Experiment')\n",
    "features = list(df.keys()[:index]) + ['Wavelength(nm)']\n",
    "labels = ['Fluorescence_norm']\n",
    "features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def train_model(train, test):\n",
    "    model = XGBRegressor(\n",
    "    eval_metric=mean_absolute_error \n",
    "    )\n",
    "    \n",
    "    X_train, y_train = train[train.columns.difference(['Fluorescence', 'Fluorescence_norm'])], train['Fluorescence_norm']\n",
    "    X_test, y_test = test[test.columns.difference(['Fluorescence', 'Fluorescence_norm'])], test['Fluorescence_norm']\n",
    "    model.fit(X_train, y_train, eval_set=[(X_test, y_test)], early_stopping_rounds=5)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def test_model(model, validation):\n",
    "    val_feats = validation[validation.columns.difference(['Fluorescence', 'Fluorescence_norm'])]\n",
    "    val_labels = validation[\"Fluorescence_norm\"]\n",
    "\n",
    "    pred = model.predict(val_feats)\n",
    "    return (pred, val_labels.to_numpy(), val_feats['Wavelength(nm)'].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_out = []\n",
    "i=0\n",
    "for group, validation in df.groupby(['Experiment', 'Temperature(C)', 'Doping(%)', 'Time(min)']):\n",
    "    data = df.copy()\n",
    "    exp, T, d, t = group\n",
    "    validation = validation[features + labels]\n",
    "\n",
    "    # validation = data.query(\n",
    "    #     f'`Temperature(C)` == {T} & `Doping(%)` == {d} & `Time` == {t}'\n",
    "    # )\n",
    "    train_df = data.drop(validation.index)\n",
    "    train, test = train_test_split(train_df[features + labels], test_size=0.2, random_state=42)\n",
    "\n",
    "    model = train_model(train, test)\n",
    "\n",
    "    prediction = test_model(model, validation)\n",
    "    one_out.append((group, prediction))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "fig, axs = plt.subplots(1, 4, figsize=(16, 4))\n",
    "i=0\n",
    "for group, predictions in one_out:\n",
    "    axs = axs.flatten()\n",
    "    exp, T, d, t = group\n",
    "    if exp not in [\"8_NPL-13_(3-8-23)\", \"7_NPL-12_(3-8-23)\"] or T != 0.0 or t != 60:\n",
    "        continue\n",
    "    # title = f\"{exp}: T: {T}ºC, Doping: {d}%, Time: {t}min\"\n",
    "    title = f\"Doping: {d}%\"\n",
    "\n",
    "    if i == 0:\n",
    "        axs[i].plot(predictions[2], predictions[0], color=\"C0\", label='Prediction')\n",
    "        axs[i].plot(predictions[2], predictions[1], color=\"C1\", label='labels')\n",
    "    else:\n",
    "        axs[i].plot(predictions[2], predictions[0], color=\"C0\")\n",
    "        axs[i].plot(predictions[2], predictions[1], color=\"C1\")\n",
    "    axs[i].set_title(title)\n",
    "\n",
    "    i+=1 \n",
    "    plt.savefig(f'preds/{group}.png')\n",
    "fig.legend(loc='center', bbox_to_anchor=(0.5,0), fancybox=True, shadow=True, ncol=2)\n",
    "fig.suptitle(f\"7_NPL-12_(3-8-23) and 8_NPL-13_(3-8-23): T: 25 ºC, Time: 60 min\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.rcParams.update(\n",
    "    {\n",
    "        \"figure.figsize\": (5.0, 5.0 / 1.2),\n",
    "    }\n",
    ")\n",
    "\n",
    "for group, predictions in one_out:\n",
    "    exp, T, d, t = group\n",
    "    title = f\"{exp}: T: {T}ºC, Doping: {d}%, Time: {t}min\"\n",
    "    plt.figure()\n",
    "    sns.lineplot(x=predictions[2], y=predictions[0], label='Prediction').set(title=title)\n",
    "    sns.lineplot(x=predictions[2], y=predictions[1], label='label')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'preds/{group}.png')\n",
    "    fig.legend(loc='center', bbox_to_anchor=(0.5,0), fancybox=True, shadow=True, ncol=2)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "def _get_peaks(x, y):\n",
    "    peaks = []\n",
    "    th = 0.001\n",
    "    for i in range(1, len(x)-1):\n",
    "        if y[i] > y[i-1]+th and y[i] > y[i+1]+th:\n",
    "            peaks.append((x[i], y[i]))\n",
    "    return peaks\n",
    "\n",
    "def get_peaks(x, y):\n",
    "    x = np.array(x)\n",
    "    p1_i = np.where(x == 450)[0][0]\n",
    "    p1_e = np.where(x == 550)[0][0]\n",
    "    p2_i = np.where(x == 550)[0][0]\n",
    "    p2_e = np.where(x == 700)[0][0]\n",
    "\n",
    "    x1 = x[p1_i:p1_e]\n",
    "    y1 = y[p1_i:p1_e]\n",
    "    x2 = x[p2_i:p2_e]\n",
    "    y2 = y[p2_i:p2_e]\n",
    "\n",
    "    return x1[np.argmax(y1)], x2[np.argmax(y2)]\n",
    "\n",
    "def get_area_under_peaks(x, y, norm=None):\n",
    "    if not norm:\n",
    "        return np.trapz(y, x)\n",
    "    \n",
    "    x = np.array(x)\n",
    "    p1_i = np.where(x == 450)[0][0]\n",
    "    p1_e = np.where(x == 550)[0][0]\n",
    "    p2_i = np.where(x == 550)[0][0]\n",
    "    p2_e = np.where(x == 700)[0][0]\n",
    "\n",
    "    x1 = x[p1_i:p1_e]\n",
    "    y1 = y[p1_i:p1_e]\n",
    "    x2 = x[p2_i:p2_e]\n",
    "    y2 = y[p2_i:p2_e]\n",
    "\n",
    "    return np.trapz(y1, x1)/norm, np.trapz(y2, x2)/norm\n",
    "\n",
    "def process_spectrum(x, y, norm_area):\n",
    "    peaks = get_peaks(x, y)\n",
    "    areas = get_area_under_peaks(x, y, norm_area)\n",
    "    return peaks, areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(a, b):\n",
    "    return np.sqrt(np.mean((a - b)**2))\n",
    "\n",
    "pred_dict = {\n",
    "    \"Peak1\": [],\n",
    "    \"Peak2\": [],\n",
    "    \"Area1\": [],\n",
    "    \"Area2\": [],\n",
    "    \"Distance_peaks\": []\n",
    "}\n",
    "label_dict = {\n",
    "    \"Peak1\": [],\n",
    "    \"Peak2\": [],\n",
    "    \"Area1\": [],\n",
    "    \"Area2\": [],\n",
    "    \"Distance_peaks\": []\n",
    "}\n",
    "\n",
    "for group, predictions in one_out:\n",
    "    pred_peak = get_peaks(predictions[2], predictions[0])\n",
    "    pred_norm_area = get_area_under_peaks(predictions[2], predictions[0])\n",
    "    pred_area = get_area_under_peaks(predictions[2], predictions[0], norm=pred_norm_area)\n",
    "\n",
    "    label_peak = get_peaks(predictions[2], predictions[1])\n",
    "    label_norm_area = get_area_under_peaks(predictions[2], predictions[1])\n",
    "    label_area = get_area_under_peaks(predictions[2], predictions[1], norm=label_norm_area)\n",
    "    \n",
    "    pred_dict[\"Peak1\"].append(pred_peak[0])\n",
    "    pred_dict[\"Peak2\"].append(pred_peak[1])\n",
    "    pred_dict[\"Area1\"].append(pred_area[0])\n",
    "    pred_dict[\"Area2\"].append(pred_area[1])\n",
    "    pred_dict[\"Distance_peaks\"].append(pred_peak[1] - pred_peak[0])\n",
    "\n",
    "    label_dict[\"Peak1\"].append(label_peak[0])\n",
    "    label_dict[\"Peak2\"].append(label_peak[1])\n",
    "    label_dict[\"Area1\"].append(label_area[0])\n",
    "    label_dict[\"Area2\"].append(label_area[1])\n",
    "    label_dict[\"Distance_peaks\"].append(label_peak[1] - label_peak[0])\n",
    "    \n",
    "    #plot\n",
    "    # exp, T, d, t = group\n",
    "    # title = f\"{exp}: T: {T}ºC, Doping: {d}%, Time: {t}min\"\n",
    "    # plt.figure()\n",
    "    # sns.lineplot(x=predictions[2], y=predictions[0], label='Prediction').set(title=title)\n",
    "    # sns.lineplot(x=predictions[2], y=predictions[1], label='label')\n",
    "    # plt.legend()\n",
    "    # plt.show()    \n",
    "\n",
    "for k in pred_dict.keys():\n",
    "    print(k, rmse(np.array(pred_dict[k]), np.array(label_dict[k])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bolift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cloudpickle\n",
    "import bolift\n",
    "import seaborn as sns\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data/processed_data.csv')\n",
    "df.drop(['OD'], axis=1, inplace=True)\n",
    "df.groupby(['Temperature(C)', 'Doping(%)', 'Time(min)']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = df.keys().tolist().index('Experiment')\n",
    "features = df.keys()[:index]\n",
    "labels = df.keys()[index+1:-3]\n",
    "features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"Stock nanoplatelets have dimensions {Dimension1(nm)} nm by {Dimension2(nm)} nm and the optical density of 100x hexanes dilution of stock is {Dilution(%)} %\" \\\n",
    "                    \"recorded at 512nm. {Nano_stock_vol(mL)} mL nanoplatelets stock is diluted 7x by hexanes using {Diluted_vol(mL)} mL for each trial of doping. \" \\\n",
    "                    \"Silver acetate solution of {AgConc(M)} M is made with {AgMass(mg)} mg of silver acetate in {MeOH_vol(mL)} mL of MeOH and {H2O_vol(mL)} mL of water. \" \\\n",
    "                    \"{Doping(%)} % Ag doping requires {AgSol(uL)} uL of silver doping solution, respectively. \" \\\n",
    "                    \"The reaction was performed at 1000 rpm for {Time(min)} minutes at {Temperature(C)} oC. \" \\\n",
    "                    \"Fluorescence of each doped sample was collected as a 30x dilution with hexanes.\"\n",
    "\n",
    "s = df[features].iloc[0].to_dict()\n",
    "prompt_template.format(**s)\n",
    "prompts = []\n",
    "labels_auc1 = []\n",
    "labels_auc2 = []\n",
    "for i, r in df.iterrows():\n",
    "    s = r[features].to_dict()\n",
    "    prompts.append(prompt_template.format(**s))\n",
    "    # labels.append(r['Peak1'])\n",
    "    # labels.append(r['Peak2'])\n",
    "    labels_auc1.append(r['Area1'])\n",
    "    labels_auc2.append(r['Area2'])\n",
    "    # labels.append(r['Distance_peaks'])\n",
    "    # labels.append(r['ratioP2P1'])\n",
    "\n",
    "examples = [f\"{p}\\t{a1}\\t{a2}\" for p, a1, a2 in zip(prompts, labels_auc1, labels_auc2)]\n",
    "\n",
    "with open('Data/procedures.tsv', 'w') as f:\n",
    "    f.write(f\"prompt\\tauc1\\tauc2\\n\")\n",
    "    f.write('\\n'.join(examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "indexes = np.arange(len(prompts))\n",
    "np.random.shuffle(indexes)\n",
    "split = (len(indexes)-12)/len(indexes)\n",
    "\n",
    "train_indexes = indexes[:int(split*len(indexes))]\n",
    "test_indexes = indexes[int(split*len(indexes)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asktell = bolift.AskTellFewShotTopk(\n",
    "    prefix=\"Complete the distance between the fluorescence peaks in the spectra measured for the last experiment.\"\\\n",
    "          \" Each answer should be numeric and ends with ###.\" \\\n",
    "          \" Use the following information to complete the prompt: \\n\",\n",
    "    x_formatter=lambda x: f\"the experimental procedure: {x}\",\n",
    "    # y_name=\"position of first fluorescence peak\",\n",
    "    # y_name=\"position of second fluorescence peak\",\n",
    "    # y_name=\"area under first fluorescence peaks\",\n",
    "    # y_name=\"area under second fluorescence peaks\",\n",
    "    # y_name=\"distance between fluorescence peaks\",\n",
    "    y_name=\"ratio between area under the two fluorescence peaks\",\n",
    "    y_formatter=lambda y: f\"{y:.2f}\",\n",
    "    model=\"gpt-4\",\n",
    "    selector_k=5,\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "for i in train_indexes:\n",
    "  asktell.tell(prompts[i], labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat=[]\n",
    "y=[]\n",
    "for i in test_indexes:\n",
    "  yhat.append(asktell.predict(prompts[i]))\n",
    "  y.append(labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in test_indexes:\n",
    "  print(f\"{prompts[i]} => {labels[i]}\")\n",
    "\n",
    "[f\"{i.mean():.2f}\" for i in yhat], y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(a, b):\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    return np.sqrt(np.mean((a - b)**2))\n",
    "\n",
    "sum = 0\n",
    "print(f\"| {'predicted':^23s} | {'label':^10s} | {'AE':^10s} | \")\n",
    "n = 0\n",
    "for ihat, i in zip(yhat, y):\n",
    "  n+=1\n",
    "  mae = abs(ihat.mean()-i)\n",
    "  print(f\"| {ihat.mean():^10.2f}+/-{ihat.std():^10.2f} | {i:^10.2f} | {mae:^10.2f} |\")\n",
    "  sum += mae\n",
    "print(f\"\\n{'RMSE: ':>20s}{rmse([ihat.mean() for ihat in yhat], y):<18.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asktell = bolift.AskTellFewShotTopk(\n",
    "    prefix=\"Complete the distance between the fluorescence peaks in the spectra measured for the last experiment.\"\\\n",
    "          \" Each answer should be numeric and ends with ###.\" \\\n",
    "          \" Use the following information to complete the prompt: \\n\",\n",
    "    x_formatter=lambda x: f\"the experimental procedure: {x}\",\n",
    "    # y_name=\"position of first fluorescence peak\",\n",
    "    # y_name=\"position of second fluorescence peak\",\n",
    "    # y_name=\"area under first fluorescence peaks\",\n",
    "    # y_name=\"area under second fluorescence peaks\",\n",
    "    # y_name=\"distance between fluorescence peaks\",\n",
    "    y_name=\"ratio between area under the two fluorescence peaks\",\n",
    "    y_formatter=lambda y: f\"{y:.2f}\",\n",
    "    model=\"text-davinci-003\",\n",
    "    selector_k=5,\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "for p,l in zip(prompts, labels):\n",
    "  asktell.tell(p, float(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = cloudpickle.load(open('Data/pool.pkl', 'rb'))\n",
    "asktell.ask(pool, aq_fxn=\"expected_improvement\", k=5, inv_filter=14, aug_random_filter=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "doe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
